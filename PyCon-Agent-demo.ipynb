{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "api_key_prompt = \"Enter OpenAI API key:\" \n",
    "api_key = getpass(api_key_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "\n",
    "es_document_store = ElasticsearchDocumentStore(index=\"documents\", embedding_dim=1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (2.10.0)\n",
      "Requirement already satisfied: responses<0.19 in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from datasets) (2.28.2)\n",
      "Requirement already satisfied: xxhash in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from datasets) (2023.1.0)\n",
      "Requirement already satisfied: pandas in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: aiohttp in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from datasets) (10.0.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from datasets) (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: packaging in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: multiprocess in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from aiohttp->datasets) (3.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from pandas->datasets) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f5aae166644403a41ebefe891a1ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/647 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /Users/tuanacelik/.cache/huggingface/datasets/Tuana___parquet/Tuana--pycon-usa-2023-76481837ef253f5c/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b174300579f48b0a26ab6dcc84e10d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba69f1a58d3d42d284c28caa25673e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/105k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e621145fc8b4bd6b352f22180a7bc68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4645ff7be21419b87b6895ecdeb6a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/131 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /Users/tuanacelik/.cache/huggingface/datasets/Tuana___parquet/Tuana--pycon-usa-2023-76481837ef253f5c/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "remote_dataset = load_dataset('Tuana/pycon-usa-2023', split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.schema import Document\n",
    "\n",
    "documents = documents = [Document.from_dict(document) for document in remote_dataset]\n",
    "# for document in documents:\n",
    "#     document.content = document.content.replace('\\n', '<br />')\n",
    "\n",
    "es_document_store.write_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages/elasticsearch/connection/base.py:200: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n"
     ]
    }
   ],
   "source": [
    "es_document_store.delete_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Document: {'content': 'Talks: How we are making CPython faster. Past, present and future.\\nSaturday - April 22nd, 2023 2:30 p.m.-3 p.m. in\\nPresented by:\\nMark Shannon\\n\\nExperience Level:\\nSome experience\\nDescription\\nMany of you will will have heard that Python 3.11 is considerably faster than 3.10.\\nHow did we do that? How are we going to make 3.12 and following releases even faster?\\nIn this talk, I will present a high level overview of the approach we are taking to speeding up CPython.\\nStarting with a simple overview of some basic principles, I will show how we can apply those to streamline and speedup CPython.\\nI will try to avoid computer science and software engineering terminology, in favor of diagrams, a few simple examples, and some high-school math.\\nFinally, I make some estimates about how much faster the next few releases of CPython will be, and how much faster Python could go..', 'content_type': 'text', 'score': None, 'meta': {'_split_id': 0, 'url': 'https://us.pycon.org/2023/schedule/presentation/73'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd7be49403931b98bbc3e7a5d4a7ae251'}>"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_document_store.get_all_documents()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import AnswerParser, PromptNode, PromptTemplate\n",
    "from haystack.agents import Agent, Tool\n",
    "\n",
    "schedule_result = PromptTemplate(\n",
    "            name=\"zero-shot-react-schedule\", \n",
    "            prompt_text=\"You are a helpful and knowledgeable agent for PyCon attendees. To achieve your goal of creating an itinerary \"\n",
    "                        \"correctly that takes date, speaker and topic restrictions into consideration, you have access to the following tools:\\n\\n\"\n",
    "                        \"{tool_names_with_descriptions}\\n\\n\"\n",
    "                        \"To answer questions, you'll need to go through multiple steps involving step-by-step thinking and \"\n",
    "                        \"selecting appropriate tools and their inputs; tools will respond with observations.\"\n",
    "                        \"When you are ready wity an itinerary, respond with the `Itinerary:`\\n\\n\"\n",
    "                        \"Use the following format:\\n\\n\"\n",
    "                        \"Question: the question to be answered\\n\"\n",
    "                        \"Thought: Reason if you have the final itinerary. If yes, answer the query. If not, continue using the tools to create an itinerery.\\n\"\n",
    "                        \"Tool: pick one of {tool_names} \\n\"\n",
    "                        \"Tool Input: the input for the tool.\\n\"\n",
    "                        \"Observation: the tool will respond with the result\\n\"\n",
    "                        \"...\\n\"\n",
    "                        \"Itinerary: the final itinrary in chronological order with up to 5 events, where each line is one event with the time, title and speaker of the event.\\n\\n\"\n",
    "                        \"Thought, Tool, Tool Input, and Observation steps can be repeated multiple times, but sometimes we can find an answer in the first pass\\n\"\n",
    "                        \"---\\n\\n\"\n",
    "                        \"Question: {query}\\n\"\n",
    "                        \"Thought: Let's think step-by-step, I first need to \",\n",
    "        )\n",
    "\n",
    "prompt_node = PromptNode(model_name_or_path=\"text-davinci-003\", api_key=api_key, stop_words=[\"Observation:\"], max_length=1000)\n",
    "agent = Agent(prompt_node=prompt_node, prompt_template=schedule_result, final_answer_pattern=\"Itinerary\\s*:\\s*(.*)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9c5d8f00d74b6091c67afefd2bc0af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/131 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "084aabb5777c468aa0ad338a67304e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The prompt has been truncated from 522 tokens to 512 tokens to fit within the max token limit. Reduce the length of the prompt to prevent it from being cut off.\n",
      "The prompt has been truncated from 659 tokens to 512 tokens to fit within the max token limit. Reduce the length of the prompt to prevent it from being cut off.\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import BM25Retriever, EmbeddingRetriever\n",
    "\n",
    "embedding_retriever = EmbeddingRetriever(document_store= es_document_store,\n",
    "                                embedding_model='text-embedding-ada-002', \n",
    "                                batch_size = 32, \n",
    "                                api_key=api_key,\n",
    "                                top_k=7)\n",
    "\n",
    "es_document_store.update_embeddings(embedding_retriever)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever(document_store=es_document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from haystack.nodes import AnswerParser\n",
    "\n",
    "# list_events = PromptTemplate(name=\"list_events\", prompt_text=\"\"\"You will be provided a list of events such as 'Talks', 'Sponsor Presentations' or 'Tutorials'. \n",
    "#                                                                 They will appear in the following format: \\n\n",
    "                                                                \n",
    "#                                                                 Events:\n",
    "#                                                                 Type of event: Title of event\n",
    "#                                                                 Day of week - April date, time\n",
    "#                                                                 Presented by\n",
    "#                                                                 Names of presenters\n",
    "#                                                                 Description\n",
    "#                                                                 description of event\n",
    "\n",
    "#                                                                 Provide an itinerey with the date, title and short summary of each event.\n",
    "#                                                                 Filter the events based on the query where necessary and the order should \n",
    "#                                                                 be based on day of week, date and time (earliest to latest)\n",
    "                                                                \n",
    "#                                                                 Query: {query};\n",
    "#                                                                 Events: {join(documents)};\n",
    "#                                                                 Answer: \n",
    "#                                                                 \"\"\", \n",
    "                                                                \n",
    "#                                                                 output_parser=AnswerParser(),)\n",
    "list_events = PromptTemplate(name=\"list_events\", prompt_text=\"\"\"You will be provided a list of events, such as 'Talks', 'Sponsor Presentations', or 'Tutorials', in the format below:\n",
    "\n",
    "                                                                Events:\n",
    "                                                                Type of event: Title of event\n",
    "                                                                Day of week - April date, time\n",
    "                                                                Presented by\n",
    "                                                                Names of presenters\n",
    "                                                                Description\n",
    "                                                                description of event\n",
    "\n",
    "                                                                Create an itinerary for the attendee by summarizing each event in a single line. \n",
    "                                                                Filter the events based on the given query. \n",
    "                                                                Arrange the events in chronological order based on the day of the week, date, and time.\n",
    "\n",
    "                                                                Query: {query};\n",
    "                                                                Events: {join(documents)};\n",
    "                                                                Answer:\n",
    "                                                                \"\"\", \n",
    "                                                                \n",
    "                                                                output_parser=AnswerParser(),)\n",
    "\n",
    "list_builder = PromptNode(model_name_or_path=\"text-davinci-003\", api_key=api_key, max_length=300, default_prompt_template=list_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "\n",
    "event_list_by_topic_pipeline = Pipeline()\n",
    "event_list_by_topic_pipeline.add_node(component=embedding_retriever, name=\"Retriever\", inputs=[\"Query\"])\n",
    "event_list_by_topic_pipeline.add_node(component=list_builder, name=\"TopicLister\", inputs=[\"Retriever\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ce5db208e6486ba1c2cd2fcf6f3ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tuanacelik/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages/elasticsearch/connection/base.py:200: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n",
      "1 out of the 1 completions have been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n"
     ]
    }
   ],
   "source": [
    "result = event_list_by_topic_pipeline.run(\"I'm interested in NLP, what should I see?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Query: I'm interested in NLP, what should I see?\"\n",
      "'Answers:'\n",
      "[   {   'answer': 'Events (NLP): \\n'\n",
      "                  '\\n'\n",
      "                  'Tutorials: Intro to Hugging Face: Fine-tuning BERT for NLP '\n",
      "                  'tasks (Wednesday - April 19th, 2023 9 a.m.-12:30 p.m.)\\n'\n",
      "                  'Sponsor Presentations: Building LLM-based Agents: How to '\n",
      "                  'develop smart NLP-driven apps with Haystack (Thursday - '\n",
      "                  'April 20th, 2023 1:30 p.m.-2:30 p.m.)\\n'\n",
      "                  'Talks: Approaches to Fairness and Bias Mitigation in '\n",
      "                  'Natural Language Processing (Friday - April 21st, 2023 '\n",
      "                  '10:45 a.m.-11:15 a.m.)\\n'\n",
      "                  'Talks: Start thinking small: Next level Machine Learning '\n",
      "                  'with TinyML and Python (Friday - April 21st, 2023 2:30 '\n",
      "                  'p.m.-3 p.m.)\\n'\n",
      "                  'Charlas: Resolviendo crimenes con Python mediante el '\n",
      "                  'Procesamiento del Lenguaje Natural (NLP) (Saturday - April '\n",
      "                  '22nd, 2023 2:30 p.m.-3 p.m.)\\n'\n",
      "                  'Tutorials: Going beyond with Jupyter Notebooks: Write your '\n",
      "                  'first package using literate programming (Wednesday - April '\n",
      "                  '19th, 2023 9 a.m.-12:30 p.m.)\\n'\n",
      "                  'Talks: Transforming a Jupyter Notebook into a reproducible '\n",
      "                  'pipeline for ML experiments (Friday - April 21st'}]\n"
     ]
    }
   ],
   "source": [
    "from haystack.utils import print_answers\n",
    "\n",
    "print_answers(result, details=\"minimum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "either of them, as the tutorial will start from scratch. The tutorial will also be useful for experienced users, as it will show different usages and tricks to be used in the development of their projects.\n",
      "\n",
      "Itinerary: \n",
      "Tutorials: Intro to Hugging Face: Fine-tuning BERT for NLP tasks\n",
      "Wednesday - April 19th, 2023 9 a.m.-12:30 p.m. in\n",
      "Presented by:\n",
      "Juhi Chandalia\n",
      "Dana Engebretson\n",
      "\n",
      "Experience Level:\n",
      "Advance experience\n",
      "Description\n",
      "You’ve heard about ChatGPT’s conversational ability and how DALL-E can create images from a simple phrase. Now, you want to get your hands dirty training some state of the art (SOTA) deep learning models. We will use Jupyter notebooks to fine-tune an NLP model based on BERT to do sentiment analysis.\n",
      "In this hands-on tutorial, we will learn about using HuggingFace models from pre-trained open-source checkpoints and adapting these models to our own specific tasks. We will see that using SOTA NLP and computer vision models has been made easier with a combination of HuggingFace and PyTorch.\n",
      "At the end of this session, you will know how to fine-t\n"
     ]
    }
   ],
   "source": [
    "print(result[\"answers\"][0].answer.replace(\"<br />\", \"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_list_by_keyword_pipeline = Pipeline()\n",
    "event_list_by_keyword_pipeline.add_node(component=bm25_retriever, name=\"Retriever\", inputs=[\"Query\"])\n",
    "event_list_by_keyword_pipeline.add_node(component=list_builder, name=\"TopicLister\", inputs=[\"Retriever\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = event_list_by_keyword_pipeline.run(\"Tuana\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: Tuana'\n",
      "'Answers:'\n",
      "[   {   'answer': 'Thursday - April 20th, 2023 1:30 p.m.-2:30 p.m.: Sponsor '\n",
      "                  'Presentations: Building LLM-based Agents: How to develop '\n",
      "                  'smart NLP-driven apps with Haystack (Sponsor: deepset) '\n",
      "                  'presented by Tuana Celik'}]\n"
     ]
    }
   ],
   "source": [
    "print_answers(result, details=\"minimum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_search = Tool(name=\"DateSearch\", pipeline_or_node=event_list_by_keyword_pipeline, \n",
    "                           description=\"Useful for when you want to filter events based on date.\", \n",
    "                           output_variable=\"answers\")\n",
    "\n",
    "speaker_search = Tool(name=\"SpeakerSearch\", pipeline_or_node=event_list_by_keyword_pipeline, \n",
    "                           description=\"Useful for when you want to filter events based on speaker.\", \n",
    "                           output_variable=\"answers\")\n",
    "\n",
    "topic_search = Tool(name=\"TopicSearch\", pipeline_or_node=event_list_by_topic_pipeline, \n",
    "                         description=\"Useful for when you need to find events based on what the attendee is interested in.\", \n",
    "                         output_variable=\"answers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.add_tool(date_search)\n",
    "agent.add_tool(speaker_search)\n",
    "agent.add_tool(topic_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent zero-shot-react-schedule started with {'query': 'I want to learn about NLP', 'params': None}\n",
      "\u001b[32m use\u001b[0m\u001b[32m Topic\u001b[0m\u001b[32mSearch\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m:\u001b[0m\u001b[32m Topic\u001b[0m\u001b[32mSearch\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m Input\u001b[0m\u001b[32m:\u001b[0m\u001b[32m N\u001b[0m\u001b[32mLP\u001b[0m\u001b[32m\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7087134f1f5848b3a9e5f29acb51c891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The prompt has been truncated from 3927 tokens to 3797 tokens so that the prompt length and answer length (300 tokens) fit within the max token limit (4097 tokens). Reduce the length of the prompt to prevent it from being cut off.\n",
      "1 out of the 1 completions have been truncated before reaching a natural stopping point. Increase the max_tokens parameter to allow for longer completions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: \u001b[33mtareas, como la automatización de procesos de extracción de información que impactan directamente en el desarrollo de proyectos con tecnología de visión artificial.\n",
      "\n",
      "Itinerary: \n",
      "Talks: Resolviendo crimenes con Python mediante el Procesamiento del Lenguaje Natural (NLP) - Saturday - April 22nd, 2023 2:30 p.m.-3 p.m.\n",
      "Talks: Approaches to Fairness and Bias Mitigation in Natural Language Processing - Friday - April 21st, 2023 10:45 a.m.-11:15 a.m.\n",
      "Sponsor Presentations: Building LLM-based Agents: How to develop smart NLP-driven apps with Haystack (Sponsor: deepset) - Thursday - April 20th, 2023 1:30 p.m.-2:30 p.m.\n",
      "Tutorials: Intro to Hugging Face: Fine-tuning BERT for NLP tasks - Wednesday - April 19th, 2023 9 a.m.-12:30 p.m.\n",
      "Tutorials: Going beyond with Jupyter Notebooks: Write your first package using literate programming - Wednesday - April 19th, 2023 9 a.m.-12:30 p.m.\n",
      "Talks: Skyn\u001b[0m\n",
      "Thought: \u001b[32m Let\u001b[0m\u001b[32m's\u001b[0m\u001b[32m see\u001b[0m\u001b[32m if\u001b[0m\u001b[32m the\u001b[0m\u001b[32m attend\u001b[0m\u001b[32mee\u001b[0m\u001b[32m is\u001b[0m\u001b[32m interested\u001b[0m\u001b[32m in\u001b[0m\u001b[32m a\u001b[0m\u001b[32m specific\u001b[0m\u001b[32m speaker\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m:\u001b[0m\u001b[32m Speaker\u001b[0m\u001b[32mSearch\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m Input\u001b[0m\u001b[32m:\u001b[0m\u001b[32m Sk\u001b[0m\u001b[32myn\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Exception while running node 'TopicLister': Expected prompt parameters ['documents', 'query'] but got ['stop_words', 'query', 'top_k'].\nEnable debug logging to see the data that was passed when the pipeline failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages/haystack/pipelines/base.py:552\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, query, file_paths, labels, documents, meta, params, debug)\u001b[0m\n\u001b[1;32m    551\u001b[0m start \u001b[39m=\u001b[39m time()\n\u001b[0;32m--> 552\u001b[0m node_output, stream_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_node(node_id, node_input)\n\u001b[1;32m    553\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_debug\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m node_output \u001b[39mand\u001b[39;00m node_id \u001b[39min\u001b[39;00m node_output[\u001b[39m\"\u001b[39m\u001b[39m_debug\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages/haystack/pipelines/base.py:467\u001b[0m, in \u001b[0;36mPipeline._run_node\u001b[0;34m(self, node_id, node_input)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_node\u001b[39m(\u001b[39mself\u001b[39m, node_id: \u001b[39mstr\u001b[39m, node_input: Dict[\u001b[39mstr\u001b[39m, Any]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Dict, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 467\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgraph\u001b[39m.\u001b[39;49mnodes[node_id][\u001b[39m\"\u001b[39;49m\u001b[39mcomponent\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49m_dispatch_run(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnode_input)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages/haystack/nodes/base.py:201\u001b[0m, in \u001b[0;36mBaseComponent._dispatch_run\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39mThe Pipelines call this method when run() is executed. This method in turn executes the _dispatch_run_general()\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39mmethod with the correct run method.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch_run_general(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages/haystack/nodes/base.py:245\u001b[0m, in \u001b[0;36mBaseComponent._dispatch_run_general\u001b[0;34m(self, run_method, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m         run_inputs[key] \u001b[39m=\u001b[39m value\n\u001b[0;32m--> 245\u001b[0m output, stream \u001b[39m=\u001b[39m run_method(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrun_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrun_params)\n\u001b[1;32m    247\u001b[0m \u001b[39m# Collect debug information\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages/haystack/nodes/prompt/prompt_node.py:979\u001b[0m, in \u001b[0;36mPromptNode.run\u001b[0;34m(self, query, file_paths, labels, documents, meta, invocation_context, prompt_template)\u001b[0m\n\u001b[1;32m    977\u001b[0m     invocation_context[\u001b[39m\"\u001b[39m\u001b[39mprompt_template\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_prompt_template(prompt_template)\n\u001b[0;32m--> 979\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(prompt_collector\u001b[39m=\u001b[39;49mprompt_collector, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minvocation_context)\n\u001b[1;32m    981\u001b[0m prompt_template_resolved: PromptTemplate \u001b[39m=\u001b[39m invocation_context\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mprompt_template\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages/haystack/nodes/prompt/prompt_node.py:763\u001b[0m, in \u001b[0;36mPromptNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    762\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mprompt_template\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 763\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprompt(prompt_template, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    764\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages/haystack/nodes/prompt/prompt_node.py:786\u001b[0m, in \u001b[0;36mPromptNode.prompt\u001b[0;34m(self, prompt_template, *args, **kwargs)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[39mif\u001b[39;00m template_to_fill:\n\u001b[1;32m    785\u001b[0m     \u001b[39m# prompt template used, yield prompts from inputs args\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m     \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m template_to_fill\u001b[39m.\u001b[39mfill(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    787\u001b[0m         kwargs_copy \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mcopy(kwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages/haystack/nodes/prompt/prompt_node.py:375\u001b[0m, in \u001b[0;36mPromptTemplate.fill\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[39mFills the parameters defined in the prompt text with the arguments passed to it and returns the iterator prompt text.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[39m:return: An iterator of prompt texts.\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m template_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    377\u001b[0m \u001b[39m# the prompt context values should all be lists, as they will be split as one\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages/haystack/nodes/prompt/prompt_node.py:333\u001b[0m, in \u001b[0;36mPromptTemplate.prepare\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m     available_params \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\u001b[39mlist\u001b[39m(params_dict\u001b[39m.\u001b[39mkeys()) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(kwargs\u001b[39m.\u001b[39mkeys())))\n\u001b[0;32m--> 333\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected prompt parameters \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprompt_params\u001b[39m}\u001b[39;00m\u001b[39m but got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(available_params)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    335\u001b[0m template_dict \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39m_at_least_one_prompt\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m}\n",
      "\u001b[0;31mValueError\u001b[0m: Expected prompt parameters ['documents', 'query'] but got ['stop_words', 'query', 'top_k'].",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[403], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m agent\u001b[39m.\u001b[39;49mrun(\u001b[39m\"\u001b[39;49m\u001b[39mI want to learn about NLP\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages/haystack/agents/base.py:288\u001b[0m, in \u001b[0;36mAgent.run\u001b[0;34m(self, query, max_steps, params)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    287\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m agent_step\u001b[39m.\u001b[39mis_last():\n\u001b[0;32m--> 288\u001b[0m         agent_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step(agent_step, params)\n\u001b[1;32m    289\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_agent_finish(agent_step)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages/haystack/agents/base.py:321\u001b[0m, in \u001b[0;36mAgent._step\u001b[0;34m(self, current_step, params)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_agent_step(next_step)\n\u001b[1;32m    320\u001b[0m \u001b[39m# run the tool selected by the LLM\u001b[39;00m\n\u001b[0;32m--> 321\u001b[0m observation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_tool(next_step, params) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m next_step\u001b[39m.\u001b[39mis_last() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[39m# update the next step with the observation\u001b[39;00m\n\u001b[1;32m    324\u001b[0m next_step\u001b[39m.\u001b[39mcompleted(observation)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages/haystack/agents/base.py:384\u001b[0m, in \u001b[0;36mAgent._run_tool\u001b[0;34m(self, next_step, params)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    383\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_tool_error(e, tool\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtools[tool_name])\n\u001b[0;32m--> 384\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    385\u001b[0m \u001b[39mreturn\u001b[39;00m tool_result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages/haystack/agents/base.py:378\u001b[0m, in \u001b[0;36mAgent._run_tool\u001b[0;34m(self, next_step, params)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    377\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_tool_start(tool_input, tool\u001b[39m=\u001b[39mtool)\n\u001b[0;32m--> 378\u001b[0m     tool_result \u001b[39m=\u001b[39m tool\u001b[39m.\u001b[39;49mrun(tool_input, params)\n\u001b[1;32m    379\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_tool_finish(\n\u001b[1;32m    380\u001b[0m         tool_result, observation_prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mObservation: \u001b[39m\u001b[39m\"\u001b[39m, llm_prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThought: \u001b[39m\u001b[39m\"\u001b[39m, color\u001b[39m=\u001b[39mtool\u001b[39m.\u001b[39mlogging_color\n\u001b[1;32m    381\u001b[0m     )\n\u001b[1;32m    382\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages/haystack/agents/base.py:85\u001b[0m, in \u001b[0;36mTool.run\u001b[0;34m(self, tool_input, params)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m, tool_input: \u001b[39mstr\u001b[39m, params: Optional[\u001b[39mdict\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m     83\u001b[0m     \u001b[39m# We can only pass params to pipelines but not to nodes\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpipeline_or_node, (Pipeline, BaseStandardPipeline)):\n\u001b[0;32m---> 85\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpipeline_or_node\u001b[39m.\u001b[39;49mrun(query\u001b[39m=\u001b[39;49mtool_input, params\u001b[39m=\u001b[39;49mparams)\n\u001b[1;32m     86\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpipeline_or_node, BaseRetriever):\n\u001b[1;32m     87\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpipeline_or_node\u001b[39m.\u001b[39mrun(query\u001b[39m=\u001b[39mtool_input, root_node\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mQuery\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.10/site-packages/haystack/pipelines/base.py:559\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, query, file_paths, labels, documents, meta, params, debug)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    556\u001b[0m     \u001b[39m# The input might be a really large object with thousands of embeddings.\u001b[39;00m\n\u001b[1;32m    557\u001b[0m     \u001b[39m# If you really want to see it, raise the log level.\u001b[39;00m\n\u001b[1;32m    558\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mException while running node \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m with input \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, node_id, node_input)\n\u001b[0;32m--> 559\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\n\u001b[1;32m    560\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mException while running node \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mnode_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mEnable debug logging to see the data that was passed when the pipeline failed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    561\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    562\u001b[0m queue\u001b[39m.\u001b[39mpop(node_id)\n\u001b[1;32m    563\u001b[0m \u001b[39m#\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: Exception while running node 'TopicLister': Expected prompt parameters ['documents', 'query'] but got ['stop_words', 'query', 'top_k'].\nEnable debug logging to see the data that was passed when the pipeline failed."
     ]
    }
   ],
   "source": [
    "agent.run(\"I want to learn about NLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
